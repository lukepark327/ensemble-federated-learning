{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Mean & Std\n",
    "\n",
    "Calculates mean and std of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm(dataset):\n",
    "    mean = dataset.data.mean(axis=(0, 1, 2)) / 255.\n",
    "    std = dataset.data.std(axis=(0, 1, 2)) / 255.\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "\n",
    "Splits dataset into multiple subsets.\n",
    "\n",
    "### TODO\n",
    "\n",
    "- [ ] bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_by_dist(\n",
    "    dataset,\n",
    "    size: int,\n",
    "    dist: callable = None,\n",
    "    **params\n",
    "):\n",
    "    \"\"\"Split `dataset` into subsets by distribution function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : datasets\n",
    "        See `torchvision.datasets` .\n",
    "    size : int\n",
    "        Number (Length) of subsets.\n",
    "    dist : function\n",
    "        Distribution function which retures np.array.\n",
    "        Sum of returned array SHOULD be 1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : subsets\n",
    "         Of `dataset`.\n",
    "    \"\"\"\n",
    "\n",
    "    assert size != 0, \"`size` > 0\"\n",
    "\n",
    "    dist = dist or uniform  # default value\n",
    "\n",
    "    # calculates distribution `dist_val`\n",
    "    dist_val = dist(size, **params)  # dist_val: np.array\n",
    "    assert math.isclose(sum(dist_val), 1.), \"sum of `dist` SHOULD be 1.\"\n",
    "\n",
    "    N = len(dataset)\n",
    "    result = np.full(size, N) * dist_val\n",
    "    result = np.around(result).astype('int')    # to integers\n",
    "    result = result.clip(1, None)               # to positive integers\n",
    "    # adjustment for that summation of `result` SHOULD be `N`\n",
    "    result[-1] = N - sum(result[:-1])\n",
    "    while True:\n",
    "        if result[-1] < 1:\n",
    "            result[result.argmax()] -= 1\n",
    "            result[-1] += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return random_split(dataset, sorted(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(\n",
    "    size: int,\n",
    "    **params  # no longer needed\n",
    "):\n",
    "    assert len(params) == 0, \\\n",
    "        \"uniform() got an unexpected keyword argument {}\".format(\n",
    "            ', '.join([\"\"\"\\'\"\"\" + k + \"\"\"\\'\"\"\" for k in params.keys()])\n",
    "    )\n",
    "\n",
    "    return np.ones(size) / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(\n",
    "    size: int,\n",
    "    loc: float = 0.,\n",
    "    scale: float = 1.,\n",
    "    lower: float = 0.,\n",
    "    upper: float = None\n",
    "):\n",
    "    \"\"\"Calculate normal (Gaussian) distribution.\n",
    "\n",
    "    Uses `abs` to restrict to non-zeros.\n",
    "\n",
    "    In fact, it is not a normal distribution because there are only\n",
    "    positive elements in `result`.\n",
    "\n",
    "    See https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        Number (Length) of chunks.\n",
    "        Same as length of returned np.array.\n",
    "    loc : float\n",
    "        Mean (“centre”) of the distribution.\n",
    "    scale : float\n",
    "        Standard deviation (spread or “width”) of the distribution.\n",
    "        MUST be non-negative.\n",
    "    lower : float\n",
    "        Lower-bound before applying scaling.\n",
    "    upper : float\n",
    "        Upper-bound before applying scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.array\n",
    "        Returns normal (Gaussian) distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.random.normal(loc, scale, size)\n",
    "    result = abs(result)  # `result` SHOULD be only positive.\n",
    "    result = result.clip(lower, upper)\n",
    "    return result / sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto(\n",
    "    size: int,\n",
    "    alpha: float = 1.16,  # by 80-20 rule, log(5)/log(4)\n",
    "    lower: float = 0.,\n",
    "    upper: float = None\n",
    "):\n",
    "    \"\"\"Calculate Pareto distribution.\n",
    "\n",
    "    See https://numpy.org/doc/stable/reference/random/generated/numpy.random.pareto.html .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        Number (Length) of chunks.\n",
    "        Same as length of returned np.array.\n",
    "    alpha : float\n",
    "        Shape of the distribution.\n",
    "        Must be positive.\n",
    "    lower : float\n",
    "        Lower-bound before applying scaling.\n",
    "    upper : float\n",
    "        Upper-bound before applying scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.array\n",
    "        Returns Pareto distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.random.pareto(alpha, size)\n",
    "    result = result.clip(lower, upper)\n",
    "    return result / sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "(array([0.49139968, 0.48215841, 0.44653091]),\n",
      " array([0.24703223, 0.24348513, 0.26158784]))\n",
      "[200, 318, 559, 781, 955, 1116, 1466, 3230, 15064, 26311]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from pprint import pprint\n",
    "\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    \"\"\"Test `get_norm`\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    trainDataset = dset.CIFAR10(root='cifar', train=True, download=True, transform=transform)\n",
    "    pprint(get_norm(trainDataset))\n",
    "\n",
    "    \"\"\"Test `adv_random_split`\"\"\"\n",
    "    pprint([len(subset) for subset in random_split_by_dist(\n",
    "        trainDataset,\n",
    "        size=10,\n",
    "        dist=pareto,\n",
    "        alpha=2.\n",
    "    )])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('ai')",
   "metadata": {
    "interpreter": {
     "hash": "0941123111d7584689eaa3e7497f5ce25be459cf8119cfb373d11d008f067439"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}