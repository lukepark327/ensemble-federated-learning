{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation\n",
    "\n",
    "Computes the Knowledge Distillation (KD) loss and trains based on KD.\n",
    "\n",
    "Reference:\n",
    "\n",
    "* https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py#L100\n",
    "* https://github.com/IntelLabs/distiller/blob/master/distiller/knowledge_distillation.py#L135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "source": [
    "## Loss Function for KD\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* alpha\n",
    "* temperature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_KD(\n",
    "    outputs,\n",
    "    labels,\n",
    "    teacher_outputs,\n",
    "    alpha: float = 0.1,\n",
    "    temperature: float = 3.\n",
    "):\n",
    "    loss_KD = nn.KLDivLoss()(\n",
    "        F.log_softmax(outputs / temperature, dim=1),\n",
    "        F.softmax(teacher_outputs / temperature, dim=1)\n",
    "    ) * (alpha * temperature * temperature) + \\\n",
    "        F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "    return loss_KD"
   ]
  },
  {
   "source": [
    "## Train for KD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KD(\n",
    "    student, teacher, criterion_kd, optimizer, dataloader,\n",
    "    epoch: int = 0, cuda: bool = False, log: bool = False, log_file=None,\n",
    "    **params\n",
    "):\n",
    "    \"\"\"Train `student` network.\n",
    "    \n",
    "    Using KD with (pre-trained) `teacher` network.\n",
    "    \n",
    "    Refers https://keras.io/examples/vision/knowledge_distillation/ .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student : net\n",
    "        Trained by `teacher`.\n",
    "    teacher : net\n",
    "        Trains `student`.\n",
    "    criterion_kd : function\n",
    "        Loss function. See `criterion_KD`.\n",
    "    optimizer : optimizer\n",
    "        Optimizer.\n",
    "    dataloader : data loader\n",
    "        Data loader.\n",
    "    epoch : int\n",
    "        Current epoch information for logging.\n",
    "    cuda : bool\n",
    "        Cuda available.\n",
    "    log : bool\n",
    "        Records logs on `log_file` when `log` is True.\n",
    "        Or prints it on STDOUT.\n",
    "    log_file : (file) stream\n",
    "        Files where you want to record logs.\n",
    "    \"\"\"\n",
    "\n",
    "    student.train()  # tells student to do training\n",
    "    teacher.eval()  # tells teacher to eval\n",
    "\n",
    "    # for log\n",
    "    nProcessed = 0\n",
    "    nTrain = len(dataloader.dataset)\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        if cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        # sets gradient to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward, backward, and opt\n",
    "        outputs, teacher_outputs = student(inputs), teacher(inputs)\n",
    "        loss = criterion_kd(outputs, targets, teacher_outputs, **params)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # for log\n",
    "        nProcessed += len(inputs)\n",
    "        pred = outputs.data.max(1)[1]  # get the index of the max log-probability\n",
    "        incorrect = pred.ne(targets.data).cpu().sum()  # ne: not equal\n",
    "        err = 100. * incorrect / len(inputs)\n",
    "        partialEpoch = epoch + batch_idx / len(dataloader)\n",
    "\n",
    "        if log and (log_file is not None):  # saves at csv file\n",
    "            log_file.write('{},{},{}\\n'.format(partialEpoch, loss.item(), err))\n",
    "            log_file.flush()\n",
    "        else:  # print at STDOUT\n",
    "            print('Train Epoch: {:.2f} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tError: {:.6f}'.format(\n",
    "                partialEpoch, nProcessed, nTrain, 100. * batch_idx / len(dataloader), loss.item(), err\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27648/50000 (55%)]\tLoss: 3.089424\tError: 70.312500\n",
      "Train Epoch: 0.55 [27904/50000 (55%)]\tLoss: 2.313818\tError: 58.984375\n",
      "Train Epoch: 0.56 [28160/50000 (56%)]\tLoss: 2.792085\tError: 65.625000\n",
      "Train Epoch: 0.56 [28416/50000 (56%)]\tLoss: 3.181015\tError: 68.359375\n",
      "Train Epoch: 0.57 [28672/50000 (57%)]\tLoss: 2.419380\tError: 60.937500\n",
      "Train Epoch: 0.57 [28928/50000 (57%)]\tLoss: 2.353331\tError: 58.593750\n",
      "Train Epoch: 0.58 [29184/50000 (58%)]\tLoss: 2.739406\tError: 67.578125\n",
      "Train Epoch: 0.58 [29440/50000 (58%)]\tLoss: 2.025217\tError: 55.078125\n",
      "Train Epoch: 0.59 [29696/50000 (59%)]\tLoss: 2.255985\tError: 57.031250\n",
      "Train Epoch: 0.59 [29952/50000 (59%)]\tLoss: 2.135898\tError: 56.640625\n",
      "Train Epoch: 0.60 [30208/50000 (60%)]\tLoss: 2.647851\tError: 63.281250\n",
      "Train Epoch: 0.60 [30464/50000 (60%)]\tLoss: 1.985417\tError: 57.031250\n",
      "Train Epoch: 0.61 [30720/50000 (61%)]\tLoss: 2.482765\tError: 63.281250\n",
      "Train Epoch: 0.61 [30976/50000 (61%)]\tLoss: 2.456460\tError: 61.718750\n",
      "Train Epoch: 0.62 [31232/50000 (62%)]\tLoss: 2.213173\tError: 61.328125\n",
      "Train Epoch: 0.62 [31488/50000 (62%)]\tLoss: 2.199342\tError: 55.468750\n",
      "Train Epoch: 0.63 [31744/50000 (63%)]\tLoss: 2.282118\tError: 58.984375\n",
      "Train Epoch: 0.63 [32000/50000 (63%)]\tLoss: 2.169227\tError: 57.812500\n",
      "Train Epoch: 0.64 [32256/50000 (64%)]\tLoss: 2.429708\tError: 62.109375\n",
      "Train Epoch: 0.64 [32512/50000 (64%)]\tLoss: 2.427998\tError: 63.281250\n",
      "Train Epoch: 0.65 [32768/50000 (65%)]\tLoss: 2.253961\tError: 61.718750\n",
      "Train Epoch: 0.65 [33024/50000 (65%)]\tLoss: 1.991936\tError: 49.218750\n",
      "Train Epoch: 0.66 [33280/50000 (66%)]\tLoss: 1.949301\tError: 55.078125\n",
      "Train Epoch: 0.66 [33536/50000 (66%)]\tLoss: 2.066169\tError: 59.765625\n",
      "Train Epoch: 0.67 [33792/50000 (67%)]\tLoss: 2.126798\tError: 55.468750\n",
      "Train Epoch: 0.67 [34048/50000 (67%)]\tLoss: 1.725490\tError: 51.953125\n",
      "Train Epoch: 0.68 [34304/50000 (68%)]\tLoss: 2.134378\tError: 62.500000\n",
      "Train Epoch: 0.68 [34560/50000 (68%)]\tLoss: 1.905507\tError: 60.546875\n",
      "Train Epoch: 0.69 [34816/50000 (69%)]\tLoss: 1.978980\tError: 55.078125\n",
      "Train Epoch: 0.69 [35072/50000 (69%)]\tLoss: 2.380198\tError: 64.062500\n",
      "Train Epoch: 0.70 [35328/50000 (70%)]\tLoss: 1.900674\tError: 60.937500\n",
      "Train Epoch: 0.70 [35584/50000 (70%)]\tLoss: 2.056436\tError: 55.468750\n",
      "Train Epoch: 0.71 [35840/50000 (71%)]\tLoss: 2.040493\tError: 58.593750\n",
      "Train Epoch: 0.71 [36096/50000 (71%)]\tLoss: 2.124709\tError: 56.250000\n",
      "Train Epoch: 0.72 [36352/50000 (72%)]\tLoss: 1.949329\tError: 59.375000\n",
      "Train Epoch: 0.72 [36608/50000 (72%)]\tLoss: 1.702198\tError: 54.687500\n",
      "Train Epoch: 0.73 [36864/50000 (73%)]\tLoss: 1.951632\tError: 59.375000\n",
      "Train Epoch: 0.73 [37120/50000 (73%)]\tLoss: 1.748446\tError: 53.906250\n",
      "Train Epoch: 0.74 [37376/50000 (74%)]\tLoss: 2.012964\tError: 60.546875\n",
      "Train Epoch: 0.74 [37632/50000 (74%)]\tLoss: 1.886944\tError: 59.375000\n",
      "Train Epoch: 0.75 [37888/50000 (75%)]\tLoss: 2.158742\tError: 58.203125\n",
      "Train Epoch: 0.76 [38144/50000 (76%)]\tLoss: 1.787819\tError: 52.343750\n",
      "Train Epoch: 0.76 [38400/50000 (76%)]\tLoss: 1.891540\tError: 58.593750\n",
      "Train Epoch: 0.77 [38656/50000 (77%)]\tLoss: 2.106679\tError: 61.718750\n",
      "Train Epoch: 0.77 [38912/50000 (77%)]\tLoss: 1.871124\tError: 58.203125\n",
      "Train Epoch: 0.78 [39168/50000 (78%)]\tLoss: 1.968174\tError: 62.890625\n",
      "Train Epoch: 0.78 [39424/50000 (78%)]\tLoss: 1.881301\tError: 57.031250\n",
      "Train Epoch: 0.79 [39680/50000 (79%)]\tLoss: 1.969002\tError: 60.937500\n",
      "Train Epoch: 0.79 [39936/50000 (79%)]\tLoss: 1.896293\tError: 58.593750\n",
      "Train Epoch: 0.80 [40192/50000 (80%)]\tLoss: 1.904027\tError: 60.156250\n",
      "Train Epoch: 0.80 [40448/50000 (80%)]\tLoss: 1.868663\tError: 60.937500\n",
      "Train Epoch: 0.81 [40704/50000 (81%)]\tLoss: 1.928702\tError: 57.812500\n",
      "Train Epoch: 0.81 [40960/50000 (81%)]\tLoss: 1.949734\tError: 55.468750\n",
      "Train Epoch: 0.82 [41216/50000 (82%)]\tLoss: 2.356213\tError: 62.500000\n",
      "Train Epoch: 0.82 [41472/50000 (82%)]\tLoss: 1.941523\tError: 59.375000\n",
      "Train Epoch: 0.83 [41728/50000 (83%)]\tLoss: 2.386479\tError: 63.281250\n",
      "Train Epoch: 0.83 [41984/50000 (83%)]\tLoss: 2.010367\tError: 55.078125\n",
      "Train Epoch: 0.84 [42240/50000 (84%)]\tLoss: 2.062716\tError: 58.593750\n",
      "Train Epoch: 0.84 [42496/50000 (84%)]\tLoss: 2.138552\tError: 58.984375\n",
      "Train Epoch: 0.85 [42752/50000 (85%)]\tLoss: 2.205860\tError: 58.593750\n",
      "Train Epoch: 0.85 [43008/50000 (85%)]\tLoss: 2.029413\tError: 59.375000\n",
      "Train Epoch: 0.86 [43264/50000 (86%)]\tLoss: 2.311668\tError: 63.671875\n",
      "Train Epoch: 0.86 [43520/50000 (86%)]\tLoss: 2.169987\tError: 62.109375\n",
      "Train Epoch: 0.87 [43776/50000 (87%)]\tLoss: 2.143809\tError: 60.937500\n",
      "Train Epoch: 0.87 [44032/50000 (87%)]\tLoss: 2.225237\tError: 64.843750\n",
      "Train Epoch: 0.88 [44288/50000 (88%)]\tLoss: 1.880991\tError: 59.765625\n",
      "Train Epoch: 0.88 [44544/50000 (88%)]\tLoss: 2.237238\tError: 64.062500\n",
      "Train Epoch: 0.89 [44800/50000 (89%)]\tLoss: 2.203742\tError: 60.937500\n",
      "Train Epoch: 0.89 [45056/50000 (89%)]\tLoss: 2.131091\tError: 62.500000\n",
      "Train Epoch: 0.90 [45312/50000 (90%)]\tLoss: 2.681886\tError: 62.500000\n",
      "Train Epoch: 0.90 [45568/50000 (90%)]\tLoss: 2.119950\tError: 60.937500\n",
      "Train Epoch: 0.91 [45824/50000 (91%)]\tLoss: 1.995607\tError: 63.281250\n",
      "Train Epoch: 0.91 [46080/50000 (91%)]\tLoss: 2.165134\tError: 61.718750\n",
      "Train Epoch: 0.92 [46336/50000 (92%)]\tLoss: 1.905715\tError: 57.421875\n",
      "Train Epoch: 0.92 [46592/50000 (92%)]\tLoss: 1.952164\tError: 60.937500\n",
      "Train Epoch: 0.93 [46848/50000 (93%)]\tLoss: 2.045437\tError: 62.890625\n",
      "Train Epoch: 0.93 [47104/50000 (93%)]\tLoss: 1.860445\tError: 58.203125\n",
      "Train Epoch: 0.94 [47360/50000 (94%)]\tLoss: 2.242467\tError: 67.578125\n",
      "Train Epoch: 0.94 [47616/50000 (94%)]\tLoss: 1.989182\tError: 59.375000\n",
      "Train Epoch: 0.95 [47872/50000 (95%)]\tLoss: 1.902483\tError: 57.421875\n",
      "Train Epoch: 0.95 [48128/50000 (95%)]\tLoss: 1.970750\tError: 60.546875\n",
      "Train Epoch: 0.96 [48384/50000 (96%)]\tLoss: 1.794183\tError: 58.203125\n",
      "Train Epoch: 0.96 [48640/50000 (96%)]\tLoss: 1.973090\tError: 60.156250\n",
      "Train Epoch: 0.97 [48896/50000 (97%)]\tLoss: 2.055874\tError: 59.375000\n",
      "Train Epoch: 0.97 [49152/50000 (97%)]\tLoss: 1.848704\tError: 58.984375\n",
      "Train Epoch: 0.98 [49408/50000 (98%)]\tLoss: 1.712043\tError: 53.515625\n",
      "Train Epoch: 0.98 [49664/50000 (98%)]\tLoss: 1.897285\tError: 61.718750\n",
      "Train Epoch: 0.99 [49920/50000 (99%)]\tLoss: 1.771357\tError: 53.125000\n",
      "Train Epoch: 0.99 [50000/50000 (99%)]\tLoss: 2.155463\tError: 60.000000\n",
      "\n",
      "Test Set\tAverage Loss: 2.7340\tError: 5922.0/10000 (59.220001%)\n",
      "\n",
      "Train Epoch: 1.00 [256/50000 (0%)]\tLoss: 2.035429\tError: 61.328125\n",
      "Train Epoch: 1.01 [512/50000 (1%)]\tLoss: 1.780919\tError: 55.078125\n",
      "Train Epoch: 1.01 [768/50000 (1%)]\tLoss: 1.917849\tError: 58.203125\n",
      "Train Epoch: 1.02 [1024/50000 (2%)]\tLoss: 1.731164\tError: 55.078125\n",
      "Train Epoch: 1.02 [1280/50000 (2%)]\tLoss: 1.803964\tError: 53.125000\n",
      "Train Epoch: 1.03 [1536/50000 (3%)]\tLoss: 2.072934\tError: 61.718750\n",
      "Train Epoch: 1.03 [1792/50000 (3%)]\tLoss: 1.683310\tError: 53.906250\n",
      "Train Epoch: 1.04 [2048/50000 (4%)]\tLoss: 2.089212\tError: 60.937500\n",
      "Train Epoch: 1.04 [2304/50000 (4%)]\tLoss: 2.156814\tError: 63.281250\n",
      "Train Epoch: 1.05 [2560/50000 (5%)]\tLoss: 1.955775\tError: 58.203125\n",
      "Train Epoch: 1.05 [2816/50000 (5%)]\tLoss: 2.134365\tError: 64.062500\n",
      "Train Epoch: 1.06 [3072/50000 (6%)]\tLoss: 1.776469\tError: 54.687500\n",
      "Train Epoch: 1.06 [3328/50000 (6%)]\tLoss: 1.929020\tError: 59.765625\n",
      "Train Epoch: 1.07 [3584/50000 (7%)]\tLoss: 2.047430\tError: 57.421875\n",
      "Train Epoch: 1.07 [3840/50000 (7%)]\tLoss: 1.903411\tError: 60.937500\n",
      "Train Epoch: 1.08 [4096/50000 (8%)]\tLoss: 1.982362\tError: 58.593750\n",
      "Train Epoch: 1.08 [4352/50000 (8%)]\tLoss: 1.783055\tError: 55.468750\n",
      "Train Epoch: 1.09 [4608/50000 (9%)]\tLoss: 1.656215\tError: 51.171875\n",
      "Train Epoch: 1.09 [4864/50000 (9%)]\tLoss: 2.107693\tError: 62.109375\n",
      "Train Epoch: 1.10 [5120/50000 (10%)]\tLoss: 1.961541\tError: 59.765625\n",
      "Train Epoch: 1.10 [5376/50000 (10%)]\tLoss: 1.874550\tError: 55.859375\n",
      "Train Epoch: 1.11 [5632/50000 (11%)]\tLoss: 2.076591\tError: 59.765625\n",
      "Train Epoch: 1.11 [5888/50000 (11%)]\tLoss: 1.715622\tError: 56.640625\n",
      "Train Epoch: 1.12 [6144/50000 (12%)]\tLoss: 2.002969\tError: 59.375000\n",
      "Train Epoch: 1.12 [6400/50000 (12%)]\tLoss: 2.013133\tError: 61.718750\n",
      "Train Epoch: 1.13 [6656/50000 (13%)]\tLoss: 1.706033\tError: 56.640625\n",
      "Train Epoch: 1.13 [6912/50000 (13%)]\tLoss: 1.813193\tError: 55.859375\n",
      "Train Epoch: 1.14 [7168/50000 (14%)]\tLoss: 1.674298\tError: 51.953125\n",
      "Train Epoch: 1.14 [7424/50000 (14%)]\tLoss: 1.695279\tError: 55.859375\n",
      "Train Epoch: 1.15 [7680/50000 (15%)]\tLoss: 1.873616\tError: 56.640625\n",
      "Train Epoch: 1.15 [7936/50000 (15%)]\tLoss: 1.910630\tError: 56.250000\n",
      "Train Epoch: 1.16 [8192/50000 (16%)]\tLoss: 1.893852\tError: 53.906250\n",
      "Train Epoch: 1.16 [8448/50000 (16%)]\tLoss: 1.595834\tError: 55.859375\n",
      "Train Epoch: 1.17 [8704/50000 (17%)]\tLoss: 1.740063\tError: 55.859375\n",
      "Train Epoch: 1.17 [8960/50000 (17%)]\tLoss: 2.188204\tError: 64.062500\n",
      "Train Epoch: 1.18 [9216/50000 (18%)]\tLoss: 1.975538\tError: 60.156250\n",
      "Train Epoch: 1.18 [9472/50000 (18%)]\tLoss: 1.697728\tError: 51.562500\n",
      "Train Epoch: 1.19 [9728/50000 (19%)]\tLoss: 1.995587\tError: 62.500000\n",
      "Train Epoch: 1.19 [9984/50000 (19%)]\tLoss: 1.919657\tError: 62.500000\n",
      "Train Epoch: 1.20 [10240/50000 (20%)]\tLoss: 2.043553\tError: 62.500000\n",
      "Train Epoch: 1.20 [10496/50000 (20%)]\tLoss: 1.936189\tError: 52.734375\n",
      "Train Epoch: 1.21 [10752/50000 (21%)]\tLoss: 1.867264\tError: 59.765625\n",
      "Train Epoch: 1.21 [11008/50000 (21%)]\tLoss: 2.112853\tError: 66.015625\n",
      "Train Epoch: 1.22 [11264/50000 (22%)]\tLoss: 2.003749\tError: 60.156250\n",
      "Train Epoch: 1.22 [11520/50000 (22%)]\tLoss: 2.226696\tError: 64.453125\n",
      "Train Epoch: 1.23 [11776/50000 (23%)]\tLoss: 2.071970\tError: 61.328125\n",
      "Train Epoch: 1.23 [12032/50000 (23%)]\tLoss: 2.495134\tError: 65.234375\n",
      "Train Epoch: 1.24 [12288/50000 (24%)]\tLoss: 2.327974\tError: 66.015625\n",
      "Train Epoch: 1.24 [12544/50000 (24%)]\tLoss: 2.128519\tError: 60.937500\n",
      "Train Epoch: 1.25 [12800/50000 (25%)]\tLoss: 2.547263\tError: 66.015625\n",
      "Train Epoch: 1.26 [13056/50000 (26%)]\tLoss: 1.995471\tError: 61.328125\n",
      "Train Epoch: 1.26 [13312/50000 (26%)]\tLoss: 2.435559\tError: 63.281250\n",
      "Train Epoch: 1.27 [13568/50000 (27%)]\tLoss: 2.832901\tError: 69.531250\n",
      "Train Epoch: 1.27 [13824/50000 (27%)]\tLoss: 2.566744\tError: 63.671875\n",
      "Train Epoch: 1.28 [14080/50000 (28%)]\tLoss: 2.810927\tError: 69.140625\n",
      "Train Epoch: 1.28 [14336/50000 (28%)]\tLoss: 1.942755\tError: 58.593750\n",
      "Train Epoch: 1.29 [14592/50000 (29%)]\tLoss: 2.370071\tError: 65.625000\n",
      "Train Epoch: 1.29 [14848/50000 (29%)]\tLoss: 2.403043\tError: 64.453125\n",
      "Train Epoch: 1.30 [15104/50000 (30%)]\tLoss: 2.516900\tError: 63.671875\n",
      "Train Epoch: 1.30 [15360/50000 (30%)]\tLoss: 2.392096\tError: 65.234375\n",
      "Train Epoch: 1.31 [15616/50000 (31%)]\tLoss: 2.312005\tError: 61.718750\n",
      "Train Epoch: 1.31 [15872/50000 (31%)]\tLoss: 2.330493\tError: 62.890625\n",
      "Train Epoch: 1.32 [16128/50000 (32%)]\tLoss: 2.620588\tError: 64.453125\n",
      "Train Epoch: 1.32 [16384/50000 (32%)]\tLoss: 2.553042\tError: 64.062500\n",
      "Train Epoch: 1.33 [16640/50000 (33%)]\tLoss: 1.993629\tError: 61.328125\n",
      "Train Epoch: 1.33 [16896/50000 (33%)]\tLoss: 3.141153\tError: 74.609375\n",
      "Train Epoch: 1.34 [17152/50000 (34%)]\tLoss: 2.291265\tError: 62.109375\n",
      "Train Epoch: 1.34 [17408/50000 (34%)]\tLoss: 2.445183\tError: 65.234375\n",
      "Train Epoch: 1.35 [17664/50000 (35%)]\tLoss: 3.268897\tError: 67.968750\n",
      "Train Epoch: 1.35 [17920/50000 (35%)]\tLoss: 2.463313\tError: 59.765625\n",
      "Train Epoch: 1.36 [18176/50000 (36%)]\tLoss: 2.110871\tError: 63.281250\n",
      "Train Epoch: 1.36 [18432/50000 (36%)]\tLoss: 2.538992\tError: 69.921875\n",
      "Train Epoch: 1.37 [18688/50000 (37%)]\tLoss: 2.382193\tError: 62.109375\n",
      "Train Epoch: 1.37 [18944/50000 (37%)]\tLoss: 2.698108\tError: 66.015625\n",
      "Train Epoch: 1.38 [19200/50000 (38%)]\tLoss: 2.567240\tError: 62.109375\n",
      "Train Epoch: 1.38 [19456/50000 (38%)]\tLoss: 2.095974\tError: 55.078125\n",
      "Train Epoch: 1.39 [19712/50000 (39%)]\tLoss: 3.014878\tError: 68.750000\n",
      "Train Epoch: 1.39 [19968/50000 (39%)]\tLoss: 1.946757\tError: 56.640625\n",
      "Train Epoch: 1.40 [20224/50000 (40%)]\tLoss: 2.619543\tError: 62.500000\n",
      "Train Epoch: 1.40 [20480/50000 (40%)]\tLoss: 2.608844\tError: 67.578125\n",
      "Train Epoch: 1.41 [20736/50000 (41%)]\tLoss: 2.030764\tError: 58.984375\n",
      "Train Epoch: 1.41 [20992/50000 (41%)]\tLoss: 2.050920\tError: 61.328125\n",
      "Train Epoch: 1.42 [21248/50000 (42%)]\tLoss: 2.561692\tError: 64.843750\n",
      "Train Epoch: 1.42 [21504/50000 (42%)]\tLoss: 2.411899\tError: 65.234375\n",
      "Train Epoch: 1.43 [21760/50000 (43%)]\tLoss: 2.643280\tError: 69.531250\n",
      "Train Epoch: 1.43 [22016/50000 (43%)]\tLoss: 2.515348\tError: 62.500000\n",
      "Train Epoch: 1.44 [22272/50000 (44%)]\tLoss: 2.280933\tError: 58.593750\n",
      "Train Epoch: 1.44 [22528/50000 (44%)]\tLoss: 2.208628\tError: 60.156250\n",
      "Train Epoch: 1.45 [22784/50000 (45%)]\tLoss: 2.250766\tError: 62.890625\n",
      "Train Epoch: 1.45 [23040/50000 (45%)]\tLoss: 2.170103\tError: 53.906250\n",
      "Train Epoch: 1.46 [23296/50000 (46%)]\tLoss: 2.182601\tError: 57.031250\n",
      "Train Epoch: 1.46 [23552/50000 (46%)]\tLoss: 1.993257\tError: 61.718750\n",
      "Train Epoch: 1.47 [23808/50000 (47%)]\tLoss: 2.102836\tError: 57.421875\n",
      "Train Epoch: 1.47 [24064/50000 (47%)]\tLoss: 1.929385\tError: 60.156250\n",
      "Train Epoch: 1.48 [24320/50000 (48%)]\tLoss: 1.986660\tError: 61.718750\n",
      "Train Epoch: 1.48 [24576/50000 (48%)]\tLoss: 2.101864\tError: 58.984375\n",
      "Train Epoch: 1.49 [24832/50000 (49%)]\tLoss: 2.097038\tError: 62.500000\n",
      "Train Epoch: 1.49 [25088/50000 (49%)]\tLoss: 2.027576\tError: 55.859375\n",
      "Train Epoch: 1.50 [25344/50000 (50%)]\tLoss: 2.411728\tError: 64.843750\n",
      "Train Epoch: 1.51 [25600/50000 (51%)]\tLoss: 1.944857\tError: 59.375000\n",
      "Train Epoch: 1.51 [25856/50000 (51%)]\tLoss: 1.803816\tError: 57.031250\n",
      "Train Epoch: 1.52 [26112/50000 (52%)]\tLoss: 1.864807\tError: 58.984375\n",
      "Train Epoch: 1.52 [26368/50000 (52%)]\tLoss: 2.105468\tError: 60.546875\n",
      "Train Epoch: 1.53 [26624/50000 (53%)]\tLoss: 1.860600\tError: 56.250000\n",
      "Train Epoch: 1.53 [26880/50000 (53%)]\tLoss: 2.100049\tError: 62.500000\n",
      "Train Epoch: 1.54 [27136/50000 (54%)]\tLoss: 2.016667\tError: 58.984375\n",
      "Train Epoch: 1.54 [27392/50000 (54%)]\tLoss: 1.628936\tError: 51.953125\n",
      "Train Epoch: 1.55 [27648/50000 (55%)]\tLoss: 2.277851\tError: 61.328125\n",
      "Train Epoch: 1.55 [27904/50000 (55%)]\tLoss: 1.806543\tError: 57.421875\n",
      "Train Epoch: 1.56 [28160/50000 (56%)]\tLoss: 2.234640\tError: 62.500000\n",
      "Train Epoch: 1.56 [28416/50000 (56%)]\tLoss: 1.903356\tError: 60.937500\n",
      "Train Epoch: 1.57 [28672/50000 (57%)]\tLoss: 2.280422\tError: 65.625000\n",
      "Train Epoch: 1.57 [28928/50000 (57%)]\tLoss: 1.967460\tError: 60.937500\n",
      "Train Epoch: 1.58 [29184/50000 (58%)]\tLoss: 2.324290\tError: 63.281250\n",
      "Train Epoch: 1.58 [29440/50000 (58%)]\tLoss: 2.660699\tError: 65.234375\n",
      "Train Epoch: 1.59 [29696/50000 (59%)]\tLoss: 2.158375\tError: 65.234375\n",
      "Train Epoch: 1.59 [29952/50000 (59%)]\tLoss: 2.155589\tError: 64.843750\n",
      "Train Epoch: 1.60 [30208/50000 (60%)]\tLoss: 2.343588\tError: 66.015625\n",
      "Train Epoch: 1.60 [30464/50000 (60%)]\tLoss: 2.013149\tError: 57.812500\n",
      "Train Epoch: 1.61 [30720/50000 (61%)]\tLoss: 2.107962\tError: 58.203125\n",
      "Train Epoch: 1.61 [30976/50000 (61%)]\tLoss: 2.210767\tError: 59.765625\n",
      "Train Epoch: 1.62 [31232/50000 (62%)]\tLoss: 2.187165\tError: 62.500000\n",
      "Train Epoch: 1.62 [31488/50000 (62%)]\tLoss: 1.957861\tError: 60.546875\n",
      "Train Epoch: 1.63 [31744/50000 (63%)]\tLoss: 1.923563\tError: 55.078125\n",
      "Train Epoch: 1.63 [32000/50000 (63%)]\tLoss: 1.966076\tError: 60.156250\n",
      "Train Epoch: 1.64 [32256/50000 (64%)]\tLoss: 1.637110\tError: 53.125000\n",
      "Train Epoch: 1.64 [32512/50000 (64%)]\tLoss: 2.094378\tError: 58.203125\n",
      "Train Epoch: 1.65 [32768/50000 (65%)]\tLoss: 1.971684\tError: 61.328125\n",
      "Train Epoch: 1.65 [33024/50000 (65%)]\tLoss: 1.766680\tError: 51.953125\n",
      "Train Epoch: 1.66 [33280/50000 (66%)]\tLoss: 1.847700\tError: 54.296875\n",
      "Train Epoch: 1.66 [33536/50000 (66%)]\tLoss: 1.840757\tError: 57.031250\n",
      "Train Epoch: 1.67 [33792/50000 (67%)]\tLoss: 1.882520\tError: 59.765625\n",
      "Train Epoch: 1.67 [34048/50000 (67%)]\tLoss: 2.061432\tError: 59.375000\n",
      "Train Epoch: 1.68 [34304/50000 (68%)]\tLoss: 1.745901\tError: 58.984375\n",
      "Train Epoch: 1.68 [34560/50000 (68%)]\tLoss: 2.013727\tError: 58.203125\n",
      "Train Epoch: 1.69 [34816/50000 (69%)]\tLoss: 1.925214\tError: 57.421875\n",
      "Train Epoch: 1.69 [35072/50000 (69%)]\tLoss: 1.717735\tError: 57.031250\n",
      "Train Epoch: 1.70 [35328/50000 (70%)]\tLoss: 1.645366\tError: 53.125000\n",
      "Train Epoch: 1.70 [35584/50000 (70%)]\tLoss: 1.837628\tError: 56.640625\n",
      "Train Epoch: 1.71 [35840/50000 (71%)]\tLoss: 1.843759\tError: 55.078125\n",
      "Train Epoch: 1.71 [36096/50000 (71%)]\tLoss: 2.052725\tError: 59.765625\n",
      "Train Epoch: 1.72 [36352/50000 (72%)]\tLoss: 2.301981\tError: 60.937500\n",
      "Train Epoch: 1.72 [36608/50000 (72%)]\tLoss: 1.787987\tError: 48.437500\n",
      "Train Epoch: 1.73 [36864/50000 (73%)]\tLoss: 2.163618\tError: 59.375000\n",
      "Train Epoch: 1.73 [37120/50000 (73%)]\tLoss: 2.015338\tError: 58.984375\n",
      "Train Epoch: 1.74 [37376/50000 (74%)]\tLoss: 1.771092\tError: 59.375000\n",
      "Train Epoch: 1.74 [37632/50000 (74%)]\tLoss: 2.148049\tError: 62.109375\n",
      "Train Epoch: 1.75 [37888/50000 (75%)]\tLoss: 1.893388\tError: 53.125000\n",
      "Train Epoch: 1.76 [38144/50000 (76%)]\tLoss: 2.108268\tError: 61.718750\n",
      "Train Epoch: 1.76 [38400/50000 (76%)]\tLoss: 2.008960\tError: 53.515625\n",
      "Train Epoch: 1.77 [38656/50000 (77%)]\tLoss: 1.908437\tError: 56.250000\n",
      "Train Epoch: 1.77 [38912/50000 (77%)]\tLoss: 1.950173\tError: 61.718750\n",
      "Train Epoch: 1.78 [39168/50000 (78%)]\tLoss: 1.817603\tError: 56.640625\n",
      "Train Epoch: 1.78 [39424/50000 (78%)]\tLoss: 1.836010\tError: 55.859375\n",
      "Train Epoch: 1.79 [39680/50000 (79%)]\tLoss: 2.346716\tError: 66.015625\n",
      "Train Epoch: 1.79 [39936/50000 (79%)]\tLoss: 1.896562\tError: 56.250000\n",
      "Train Epoch: 1.80 [40192/50000 (80%)]\tLoss: 1.688823\tError: 51.562500\n",
      "Train Epoch: 1.80 [40448/50000 (80%)]\tLoss: 2.132790\tError: 66.796875\n",
      "Train Epoch: 1.81 [40704/50000 (81%)]\tLoss: 1.937756\tError: 63.671875\n",
      "Train Epoch: 1.81 [40960/50000 (81%)]\tLoss: 2.151573\tError: 58.593750\n",
      "Train Epoch: 1.82 [41216/50000 (82%)]\tLoss: 2.112568\tError: 61.718750\n",
      "Train Epoch: 1.82 [41472/50000 (82%)]\tLoss: 1.950904\tError: 58.593750\n",
      "Train Epoch: 1.83 [41728/50000 (83%)]\tLoss: 2.253273\tError: 60.546875\n",
      "Train Epoch: 1.83 [41984/50000 (83%)]\tLoss: 2.200699\tError: 58.984375\n",
      "Train Epoch: 1.84 [42240/50000 (84%)]\tLoss: 2.224629\tError: 62.109375\n",
      "Train Epoch: 1.84 [42496/50000 (84%)]\tLoss: 2.698364\tError: 69.140625\n",
      "Train Epoch: 1.85 [42752/50000 (85%)]\tLoss: 2.129424\tError: 59.375000\n",
      "Train Epoch: 1.85 [43008/50000 (85%)]\tLoss: 2.623562\tError: 61.328125\n",
      "Train Epoch: 1.86 [43264/50000 (86%)]\tLoss: 2.226459\tError: 60.156250\n",
      "Train Epoch: 1.86 [43520/50000 (86%)]\tLoss: 2.505359\tError: 62.109375\n",
      "Train Epoch: 1.87 [43776/50000 (87%)]\tLoss: 2.526331\tError: 65.234375\n",
      "Train Epoch: 1.87 [44032/50000 (87%)]\tLoss: 2.039263\tError: 56.250000\n",
      "Train Epoch: 1.88 [44288/50000 (88%)]\tLoss: 2.448476\tError: 55.468750\n",
      "Train Epoch: 1.88 [44544/50000 (88%)]\tLoss: 2.621114\tError: 58.984375\n",
      "Train Epoch: 1.89 [44800/50000 (89%)]\tLoss: 2.288503\tError: 61.328125\n",
      "Train Epoch: 1.89 [45056/50000 (89%)]\tLoss: 1.854959\tError: 55.468750\n",
      "Train Epoch: 1.90 [45312/50000 (90%)]\tLoss: 2.398684\tError: 60.156250\n",
      "Train Epoch: 1.90 [45568/50000 (90%)]\tLoss: 1.946845\tError: 57.031250\n",
      "Train Epoch: 1.91 [45824/50000 (91%)]\tLoss: 2.375952\tError: 63.281250\n",
      "Train Epoch: 1.91 [46080/50000 (91%)]\tLoss: 2.308873\tError: 54.296875\n",
      "Train Epoch: 1.92 [46336/50000 (92%)]\tLoss: 2.663984\tError: 54.687500\n",
      "Train Epoch: 1.92 [46592/50000 (92%)]\tLoss: 2.103817\tError: 53.906250\n",
      "Train Epoch: 1.93 [46848/50000 (93%)]\tLoss: 2.174062\tError: 60.546875\n",
      "Train Epoch: 1.93 [47104/50000 (93%)]\tLoss: 2.728517\tError: 69.140625\n",
      "Train Epoch: 1.94 [47360/50000 (94%)]\tLoss: 2.093158\tError: 61.328125\n",
      "Train Epoch: 1.94 [47616/50000 (94%)]\tLoss: 2.205823\tError: 62.109375\n",
      "Train Epoch: 1.95 [47872/50000 (95%)]\tLoss: 2.588953\tError: 54.687500\n",
      "Train Epoch: 1.95 [48128/50000 (95%)]\tLoss: 2.393320\tError: 60.937500\n",
      "Train Epoch: 1.96 [48384/50000 (96%)]\tLoss: 1.765118\tError: 52.343750\n",
      "Train Epoch: 1.96 [48640/50000 (96%)]\tLoss: 1.909220\tError: 55.078125\n",
      "Train Epoch: 1.97 [48896/50000 (97%)]\tLoss: 2.144382\tError: 62.890625\n",
      "Train Epoch: 1.97 [49152/50000 (97%)]\tLoss: 1.889673\tError: 57.421875\n",
      "Train Epoch: 1.98 [49408/50000 (98%)]\tLoss: 1.877883\tError: 57.812500\n",
      "Train Epoch: 1.98 [49664/50000 (98%)]\tLoss: 2.218407\tError: 58.984375\n",
      "Train Epoch: 1.99 [49920/50000 (99%)]\tLoss: 2.089206\tError: 58.593750\n",
      "Train Epoch: 1.99 [50000/50000 (99%)]\tLoss: 2.020585\tError: 60.000000\n",
      "\n",
      "Test Set\tAverage Loss: 3.2866\tError: 6532.0/10000 (65.320000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    from torch.utils.data import DataLoader  # TODO: DistributedDataParallel\n",
    "\n",
    "    import import_ipynb\n",
    "    from ml import train, test\n",
    "    import nets\n",
    "\n",
    "    \"\"\"Hyperparams\"\"\"\n",
    "    numWorkers = 4\n",
    "    cuda = True\n",
    "\n",
    "    base_path = './kd'\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    trainFile = open(os.path.join(base_path, 'train.csv'), 'w')\n",
    "    testFile = open(os.path.join(base_path, 'test.csv'), 'w')\n",
    "\n",
    "    epochs = 2\n",
    "    teacher_epochs = 2\n",
    "    batchSz = 256\n",
    "\n",
    "    \"\"\"Datasets\"\"\"\n",
    "    # # gets mean and std\n",
    "    # transform = transforms.Compose([transforms.ToTensor()])\n",
    "    # dataset = dset.CIFAR10(root='cifar', train=True, download=True, transform=transform)\n",
    "    # normMean, normStd = utils.getNorm(dataset)\n",
    "    normMean = [0.49139968, 0.48215841, 0.44653091]\n",
    "    normStd = [0.24703223, 0.24348513, 0.26158784]\n",
    "    normTransform = transforms.Normalize(normMean, normStd)\n",
    "\n",
    "    trainTransform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normTransform\n",
    "    ])\n",
    "    testTransform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normTransform\n",
    "    ])\n",
    "\n",
    "    # num_workers: number of CPU cores to use for data loading\n",
    "    # pin_memory: being able to speed up the host to device transfer by enabling\n",
    "    kwargs = {'num_workers': numWorkers, 'pin_memory': cuda}\n",
    "\n",
    "    # loaders\n",
    "    trainLoader = DataLoader(\n",
    "        dset.CIFAR10(root='cifar', train=True, download=True, transform=trainTransform),\n",
    "        batch_size=batchSz, shuffle=True, **kwargs\n",
    "    )\n",
    "    testLoader = DataLoader(\n",
    "        dset.CIFAR10(root='cifar', train=False, download=True, transform=testTransform),\n",
    "        batch_size=batchSz, shuffle=False, **kwargs\n",
    "    )\n",
    "\n",
    "    \"\"\"Nets\"\"\"\n",
    "    num_classes = 10\n",
    "\n",
    "    \"\"\"`teacher`\"\"\"\n",
    "    teacher = nets.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "    # fixes parameters for `teacher`\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # replaces nodes (num_classes) of output layer (fc)\n",
    "    num_ftrs = teacher.fc.in_features\n",
    "    teacher.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # params to learn\n",
    "    params_to_update = []\n",
    "    for param in teacher.parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_update.append(param)\n",
    "\n",
    "    teacher_criterion = nn.CrossEntropyLoss()\n",
    "    teacher_optimizer = optim.SGD(params_to_update, lr=1e-1, momentum=0.9)\n",
    "\n",
    "    \"\"\"`student`\"\"\"\n",
    "    student = nets.resnet18(num_classes=num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(student.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "    if cuda:\n",
    "        # if multi-gpus\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            teacher = nn.DataParallel(teacher)\n",
    "            student = nn.DataParallel(student)\n",
    "\n",
    "        # use cuda\n",
    "        teacher.cuda()\n",
    "        student.cuda()\n",
    "\n",
    "    \"\"\"Train & Test `teacher`\"\"\"\n",
    "    for epoch in range(teacher_epochs):\n",
    "        train(\n",
    "            teacher, teacher_criterion, teacher_optimizer, trainLoader,\n",
    "            epoch=epoch, cuda=cuda\n",
    "        )\n",
    "        test(\n",
    "            teacher, criterion, testLoader,\n",
    "            epoch=epoch, cuda=cuda\n",
    "        )\n",
    "\n",
    "    \"\"\"Train & Test `student`\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        train_KD(\n",
    "            student, teacher, criterion_KD, optimizer, trainLoader,\n",
    "            epoch=epoch, cuda=cuda, log=True, log_file=trainFile,\n",
    "            alpha=0.8, temperature=5\n",
    "        )\n",
    "        test(\n",
    "            student, criterion, testLoader,\n",
    "            epoch=epoch, cuda=cuda, log=True, log_file=testFile\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}