{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "Forms an ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import import_ipynb\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, nets: list, params: dict = {}):\n",
    "        \"\"\"Forms an ensemble model and its methods\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nets: list\n",
    "            List of neural networks (models) .        \n",
    "        params: dict\n",
    "            Contains `modeFunc` and `reputations`.\n",
    "            Sum of `reputations` SHOULD be 1.\n",
    "            `len(reputations)` SHOULD be same as number of `nets`.\n",
    "        \"\"\"\n",
    "\n",
    "        self.nets = nets\n",
    "        self.num_nets = len(self.nets)\n",
    "\n",
    "        if 'modeFunc' not in params:\n",
    "            params['modeFunc'] = avg\n",
    "        if 'reputations' not in params:\n",
    "            params['reputations'] = utils.uniform(self.num_nets)\n",
    "        elif type(params['reputations']) != np.ndarray:  # list, et al.\n",
    "            params['reputations'] = np.array(params['reputations'])\n",
    "\n",
    "        modeFunc, reputations = params['modeFunc'], params['reputations']\n",
    "\n",
    "        self.set_modeFunc(modeFunc)\n",
    "        self.update_reputations(reputations)\n",
    "\n",
    "    def set_modeFunc(self, new_modeFunc: callable):\n",
    "        self.modeFunc = new_modeFunc\n",
    "\n",
    "    def update_reputations(self, new_reputations):\n",
    "        assert len(new_reputations) == self.num_nets, \\\n",
    "            \"dim of `reputations` SHOULD be same as len(nets)\"\n",
    "        assert math.isclose(sum(new_reputations), 1.), \\\n",
    "            \"sum of `reputations` shoule be 1.\"\n",
    "        if type(new_reputations) != np.ndarray:  # list, et al.\n",
    "            new_reputations = np.array(new_reputations)  # converts into np.array\n",
    "\n",
    "        self.reputations = new_reputations\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Calculates inference result of this (self) ensemble model\"\"\"\n",
    "\n",
    "        # Calculates inference result\n",
    "        outputs = list()\n",
    "        for net in self.nets:\n",
    "            outputs.append(net(inputs))\n",
    "        outputs = torch.stack(outputs)  # to Tensor\n",
    "\n",
    "        return self.modeFunc(outputs, self.reputations)\n",
    "\n",
    "    def eval(self):\n",
    "        for net in self.nets:\n",
    "            net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(outputs, reputations=None):\n",
    "    reputations = reputations if reputations is not None else utils.uniform(len(outputs))\n",
    "\n",
    "    # Calculates `result` which is the final one\n",
    "    result = torch.empty_like(outputs)\n",
    "    for net_idx, (output, reputation) in enumerate(zip(outputs, reputations)):\n",
    "        result[net_idx] = output.mul(reputation)\n",
    "\n",
    "    return torch.sum(result, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med(outputs, reputations=None):\n",
    "    \"\"\"Calculates weighted median\n",
    "    \n",
    "    See https://en.wikipedia.org/wiki/Weighted_median for weighted median.\n",
    "    \"\"\"\n",
    "\n",
    "    reputations = reputations if reputations is not None else utils.uniform(len(outputs))\n",
    "\n",
    "    # calculates sorted `outputs`' indexes\n",
    "    selectors = outputs.data.sort(dim=0)[1]  # [0]: values, [1]: indexes\n",
    "    # shape: (num_nets, batch_size, num_classes)\n",
    "    # value: which network (index of net)\n",
    "\n",
    "    # calculates sorted reputations\n",
    "    sorted_repus = torch.from_numpy(reputations)[selectors]\n",
    "\n",
    "    # selects median values\n",
    "    result = torch.empty_like(outputs[0])\n",
    "    # shape: (batch_size, num_classe)\n",
    "\n",
    "    net_max, batch_max, class_max = selectors.shape\n",
    "\n",
    "    for batch_idx in range(batch_max):\n",
    "        for class_idx in range(class_max):\n",
    "\n",
    "            accumulated_repus = 0.\n",
    "\n",
    "            for net_idx in range(net_max):\n",
    "\n",
    "                selector = selectors[net_idx][batch_idx][class_idx]  # index of selected net\n",
    "                accumulated_repus += sorted_repus[net_idx][batch_idx][class_idx]\n",
    "\n",
    "                if accumulated_repus >= 0.5:\n",
    "                    # saves median value at `result` and then `break`\n",
    "                    result[batch_idx][class_idx] = outputs[selector][batch_idx][class_idx]\n",
    "                    break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max(outputs, reputations=None):\n",
    "    \"\"\"Calculates weighted max\"\"\"\n",
    "\n",
    "    reputations = reputations if reputations is not None else utils.uniform(len(outputs))\n",
    "\n",
    "    # calculates max indexes via reputations\n",
    "    selectors = torch.empty_like(outputs)\n",
    "    for net_idx, (output, reputation) in enumerate(zip(outputs, reputations)):\n",
    "        selectors[net_idx] = output.mul(reputation)\n",
    "    selectors = selectors.data.max(dim=0)[1]  # [0]: values, [1]: indexes\n",
    "    # shape: (batch_size, num_classes)\n",
    "    # value: which network (index of net)\n",
    "\n",
    "    # selects max values\n",
    "    result = torch.empty_like(outputs[0])\n",
    "    # shape: (batch_size, num_classe)\n",
    "\n",
    "    batch_max, class_max = selectors.shape\n",
    "\n",
    "    for batch_idx in range(batch_max):\n",
    "        for class_idx in range(class_max):\n",
    "            # saves max value at `result`\n",
    "            net_idx = selectors[batch_idx][class_idx]\n",
    "            result[batch_idx][class_idx] = outputs[net_idx][batch_idx][class_idx]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from machineLearning.ipynb\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "\n",
    "    import torchvision.models as models\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    from machineLearning import train, test\n",
    "\n",
    "    \"\"\"Hyperparams\"\"\"\n",
    "    numNets = 5\n",
    "    numWorkers = 4\n",
    "    cuda = True\n",
    "\n",
    "    base_path = './ensemble'\n",
    "\n",
    "    trainFiles = [None for _ in range(numNets)]\n",
    "    testFiles = [None for _ in range(numNets)]\n",
    "    for i in range(numNets):\n",
    "        path = os.path.join(base_path, str(i))\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        trainFiles[i] = open(os.path.join(path, 'train.csv'), 'w')\n",
    "        testFiles[i] = open(os.path.join(path, 'test.csv'), 'w')\n",
    "\n",
    "    epochs = 2\n",
    "    batchSz = 256\n",
    "\n",
    "    \"\"\"Datasets\"\"\"\n",
    "    # # gets mean and std\n",
    "    # transform = transforms.Compose([transforms.ToTensor()])\n",
    "    # dataset = dset.CIFAR10(root='cifar', train=True, download=True, transform=transform)\n",
    "    # normMean, normStd = utils.getNorm(dataset)\n",
    "    normMean = [0.49139968, 0.48215841, 0.44653091]\n",
    "    normStd = [0.24703223, 0.24348513, 0.26158784]\n",
    "    normTransform = transforms.Normalize(normMean, normStd)\n",
    "\n",
    "    trainTransform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normTransform\n",
    "    ])\n",
    "    testTransform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normTransform\n",
    "    ])\n",
    "\n",
    "    trainset = dset.CIFAR10(root='cifar', train=True, download=True, transform=trainTransform)\n",
    "    testset = dset.CIFAR10(root='cifar', train=False, download=True, transform=trainTransform)\n",
    "\n",
    "    # splits datasets\n",
    "    splited_trainset = utils.random_split_by_dist(trainset, size=numNets, params={\n",
    "        'distFunc': utils.pareto,\n",
    "        'alpha': 1.16\n",
    "    })\n",
    "    splited_testset = utils.random_split_by_dist(testset, size=numNets, params={\n",
    "        'distFunc': utils.uniform\n",
    "    })\n",
    "\n",
    "    # num_workers: number of CPU cores to use for data loading\n",
    "    # pin_memory: being able to speed up the host to device transfer by enabling\n",
    "    kwargs = {'num_workers': numWorkers, 'pin_memory': cuda}\n",
    "\n",
    "    # loaders\n",
    "    trainLoaders = [DataLoader(\n",
    "        splited_trainset[i], batch_size=batchSz, shuffle=True, **kwargs\n",
    "    ) for i in range(numNets)]\n",
    "    testLoaders = [DataLoader(\n",
    "        splited_testset[i], batch_size=batchSz, shuffle=True, **kwargs\n",
    "    ) for i in range(numNets)]\n",
    "\n",
    "    \"\"\"Nets\"\"\"\n",
    "    # gets resnet18 with num_classes=10\n",
    "    # see https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L144 .\n",
    "    def _resnet18(num_classes=None):\n",
    "        if num_classes is None:\n",
    "            return models.resnet18()\n",
    "        else:\n",
    "            return models.resnet18(num_classes=num_classes)\n",
    "\n",
    "    nets = [_resnet18(num_classes=10) for _ in range(numNets)]\n",
    "\n",
    "    if cuda:\n",
    "        for net in nets:\n",
    "            net = nn.DataParallel(net)  # multi-GPUs\n",
    "            net.cuda()\n",
    "\n",
    "    criterions = [nn.CrossEntropyLoss() for _ in range(numNets)]\n",
    "    optimizers = [optim.SGD(net.parameters(), lr=1e-1, momentum=0.9) for net in nets]\n",
    "\n",
    "    \"\"\"Train & Test models\"\"\"\n",
    "    for i in range(numNets):\n",
    "        for epoch in range(epochs):\n",
    "            train(net, criterions[i], optimizers[i], trainLoaders[i], params={\n",
    "                'epoch': epoch,\n",
    "                'cuda': cuda,\n",
    "                'log': True,\n",
    "                'logFile': trainFiles[i]\n",
    "            })\n",
    "            test(net, criterions[i], testLoaders[i], params={\n",
    "                'epoch': epoch,\n",
    "                'cuda': cuda,\n",
    "                'log': True,\n",
    "                'logFile': testFiles[i]\n",
    "            })\n",
    "\n",
    "    \"\"\"Test the ensemble model\"\"\"\n",
    "    ensemble = Ensemble(nets, params={\n",
    "        'modeFunc': med,\n",
    "        'reputations': [0.05, 0.2, 0.3, 0.4, 0.05]\n",
    "    })\n",
    "\n",
    "    testFile = open(os.path.join(base_path, 'test.csv'), 'w')\n",
    "\n",
    "    for i in range(numNets):\n",
    "        test(ensemble, criterions[i], testLoaders[i], params={\n",
    "            'epoch': 0,\n",
    "            'cuda': cuda,\n",
    "            'log': True,\n",
    "            'logFile': testFile\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}